import numpy as np
import pickle
import os
import random
import math
from typing import List, Dict, Any, Tuple
from collections import defaultdict, deque
from .player import Player, PlayerAction
from .hand_evaluator import HandEvaluator
from .database import GameDatabase
from .card import Card

class ImprovedRLBot(Player):
    """æ”¹è¿›çš„å¼ºåŒ–å­¦ä¹ æœºå™¨äººï¼Œå…·æœ‰æ›´å¥½çš„å­¦ä¹ å’Œå†³ç­–èƒ½åŠ›"""
    
    def __init__(self, player_id: str, name: str, chips: int = 1000, 
                 model_path: str = "models/improved_rl_bot_model.pkl"):
        super().__init__(player_id, name, chips)
        self.model_path = model_path
        
        # æ”¹è¿›çš„å­¦ä¹ å‚æ•°
        self.learning_rate = 0.01  # é™ä½å­¦ä¹ ç‡ï¼Œé¿å…è¿‡åº¦å­¦ä¹ 
        self.discount_factor = 0.99  # æé«˜æŠ˜æ‰£å› å­ï¼Œæ›´é‡è§†é•¿æœŸå¥–åŠ±
        self.epsilon = 0.3  # æé«˜åˆå§‹æ¢ç´¢ç‡
        self.epsilon_decay = 0.9995  # æ›´æ…¢çš„è¡°å‡
        self.epsilon_min = 0.05  # ä¿æŒä¸€å®šçš„æ¢ç´¢
        
        # åŒQç½‘ç»œï¼ˆDouble Q-Learningï¼‰
        self.q_table_1 = defaultdict(lambda: defaultdict(float))
        self.q_table_2 = defaultdict(lambda: defaultdict(float))
        
        # ç»éªŒå›æ”¾
        self.experience_buffer = deque(maxlen=10000)
        self.batch_size = 32
        
        # çŠ¶æ€-åŠ¨ä½œä»·å€¼è®°å½•
        self.state_visit_count = defaultdict(int)
        self.action_count = defaultdict(lambda: defaultdict(int))
        
        # æ€§èƒ½è¿½è¸ª
        self.total_reward = 0
        self.game_count = 0
        self.win_count = 0
        
        # è®­ç»ƒè¿›åº¦è¿½è¸ª
        self.last_snapshot_game_count = 0
        self.snapshot_interval = 100  # æ¯100æ‰‹è®°å½•ä¸€æ¬¡è¿›åº¦
        
        # åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
        self.load_model()
        
        # æ•°æ®åº“è¿æ¥
        self.db = GameDatabase()
        
        # å½“å‰è½¨è¿¹
        self.current_trajectory = []
        self.hand_history = []
        
    def load_model(self):
        """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹"""
        if os.path.exists(self.model_path):
            try:
                with open(self.model_path, 'rb') as f:
                    data = pickle.load(f)
                    self.q_table_1 = data.get('q_table_1', defaultdict(lambda: defaultdict(float)))
                    self.q_table_2 = data.get('q_table_2', defaultdict(lambda: defaultdict(float)))
                    self.epsilon = data.get('epsilon', self.epsilon)
                    self.total_reward = data.get('total_reward', 0)
                    self.game_count = data.get('game_count', 0)
                    self.win_count = data.get('win_count', 0)
                    self.state_visit_count = data.get('state_visit_count', defaultdict(int))
                    self.action_count = data.get('action_count', defaultdict(lambda: defaultdict(int)))
                    print(f"âœ… å·²åŠ è½½æ”¹è¿›æ¨¡å‹: {self.model_path}")
                    print(f"   æ¸¸æˆæ¬¡æ•°: {self.game_count}, èƒœç‡: {self.win_count/max(1,self.game_count):.1%}")
            except Exception as e:
                print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
                self._initialize_empty_model()
        else:
            print(f"ğŸ“ åˆ›å»ºæ–°çš„æ”¹è¿›æ¨¡å‹: {self.model_path}")
            self._initialize_empty_model()
    
    def _initialize_empty_model(self):
        """åˆå§‹åŒ–ç©ºæ¨¡å‹"""
        self.q_table_1 = defaultdict(lambda: defaultdict(float))
        self.q_table_2 = defaultdict(lambda: defaultdict(float))
        self.state_visit_count = defaultdict(int)
        self.action_count = defaultdict(lambda: defaultdict(int))
    
    def save_model(self):
        """ä¿å­˜æ¨¡å‹åˆ°ç£ç›˜"""
        try:
            data = {
                'q_table_1': dict(self.q_table_1),
                'q_table_2': dict(self.q_table_2),
                'epsilon': self.epsilon,
                'total_reward': self.total_reward,
                'game_count': self.game_count,
                'win_count': self.win_count,
                'state_visit_count': dict(self.state_visit_count),
                'action_count': {k: dict(v) for k, v in self.action_count.items()}
            }
            with open(self.model_path, 'wb') as f:
                pickle.dump(data, f)
            print(f"ğŸ’¾ æ”¹è¿›æ¨¡å‹å·²ä¿å­˜: {self.model_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
    
    def get_enhanced_state_key(self, game_state: Dict[str, Any]) -> str:
        """è·å–å¢å¼ºçš„çŠ¶æ€è¡¨ç¤º"""
        try:
            # åŸºç¡€ä¿¡æ¯
            hand_strength = self.estimate_hand_strength(game_state)
            pot_odds = self.calculate_pot_odds(game_state)
            
            # å¯¹æ‰‹ä¿¡æ¯
            opponents_count = len([p for p in game_state.get('other_players', []) 
                                  if not p.get('is_folded', False)])
            opponents_count = max(1, min(opponents_count, 8))  # é™åˆ¶èŒƒå›´ 1-8
            
            # ä¸‹æ³¨ä¿¡æ¯
            call_amount = max(0, game_state.get('call_amount', 0))
            pot_size = max(1, game_state.get('pot', 1))  # ç¡®ä¿è‡³å°‘ä¸º1
            big_blind = max(1, game_state.get('big_blind', 20))  # ç¡®ä¿è‡³å°‘ä¸º1
            
            # æ¸¸æˆé˜¶æ®µ
            betting_round = str(game_state.get('betting_round', 'preflop'))
            
            # ç­¹ç ä¿¡æ¯
            stack_ratio = max(0, self.chips) / max(big_blind * 20, 1)  # ç›¸å¯¹äºèµ·å§‹ç­¹ç çš„æ¯”ä¾‹
            
            # ä½ç½®ä¿¡æ¯ï¼ˆç®€åŒ–ï¼‰
            position_type = self._get_position_type(opponents_count)
            
            # ä¸‹æ³¨å‹åŠ›
            bet_pressure = call_amount / pot_size
            
            # ç¦»æ•£åŒ–å„ä¸ªç»´åº¦ï¼Œç¡®ä¿å€¼åœ¨åˆç†èŒƒå›´å†…
            hand_bucket = max(0, min(int(hand_strength * 10), 9))
            
            if pot_odds == float('inf'):
                pot_odds_bucket = 10
            elif pot_odds < 0:
                pot_odds_bucket = 0
            else:
                pot_odds_bucket = min(int(pot_odds), 10)
            
            stack_bucket = max(0, min(int(stack_ratio), 10))
            pressure_bucket = max(0, min(int(bet_pressure * 5), 5))
            
            return f"{hand_bucket}_{pot_odds_bucket}_{opponents_count}_{betting_round}_{position_type}_{stack_bucket}_{pressure_bucket}"
            
        except Exception as e:
            print(f"âš ï¸  {self.name} ç”ŸæˆçŠ¶æ€é”®å‡ºç°é”™è¯¯: {e}, ä½¿ç”¨é»˜è®¤çŠ¶æ€")
            # è¿”å›é»˜è®¤çŠ¶æ€é”®
            return "0_0_2_preflop_early_5_0"
    
    def _get_position_type(self, opponents_count: int) -> str:
        """è·å–ä½ç½®ç±»å‹"""
        try:
            opponents_count = max(1, opponents_count)  # ç¡®ä¿è‡³å°‘ä¸º1
            position = getattr(self, 'position', 0)  # å®‰å…¨è·å–ä½ç½®
            
            if opponents_count <= 2:
                return "heads_up"
            elif position <= opponents_count // 3:
                return "early"
            elif position <= 2 * opponents_count // 3:
                return "middle"
            else:
                return "late"
        except (AttributeError, TypeError, ValueError):
            # å‡ºç°é”™è¯¯æ—¶è¿”å›é»˜è®¤ä½ç½®
            return "early"
    
    def get_action(self, game_state: Dict[str, Any]) -> Tuple[PlayerAction, int]:
        """è·å–åŠ¨ä½œï¼Œä½¿ç”¨æ”¹è¿›çš„ç­–ç•¥"""
        try:
            state_key = self.get_enhanced_state_key(game_state)
            available_actions = self._get_enhanced_actions(game_state)
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨åŠ¨ä½œ
            if not available_actions:
                # å¦‚æœæ²¡æœ‰å¯ç”¨åŠ¨ä½œï¼Œè¿”å›å¼ƒç‰Œ
                print(f"âš ï¸  {self.name}: æ²¡æœ‰å¯ç”¨åŠ¨ä½œï¼Œé»˜è®¤å¼ƒç‰Œ")
                return PlayerAction.FOLD, 0
            
            # è®°å½•çŠ¶æ€è®¿é—®
            self.state_visit_count[state_key] += 1
            
            # UCBï¼ˆUpper Confidence Boundï¼‰æ¢ç´¢ç­–ç•¥
            if self._should_explore(state_key):
                action_type, amount = self._ucb_action_selection(state_key, available_actions, game_state)
            else:
                # åŒQç½‘ç»œé€‰æ‹©
                action_type, amount = self._double_q_action_selection(state_key, available_actions, game_state)
            
            # éªŒè¯åŠ¨ä½œæœ‰æ•ˆæ€§
            if (action_type, amount) not in available_actions:
                print(f"âš ï¸  {self.name}: é€‰æ‹©çš„åŠ¨ä½œæ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                action_type, amount = available_actions[0]
            
            # è®°å½•è½¨è¿¹
            try:
                # å®‰å…¨åœ°å¤åˆ¶æ¸¸æˆçŠ¶æ€
                if isinstance(game_state, dict):
                    game_state_copy = game_state.copy()
                else:
                    game_state_copy = dict(game_state) if game_state else {}
                
                self.current_trajectory.append({
                    'state': state_key,
                    'action': (action_type, amount),
                    'game_state': game_state_copy
                })
            except Exception as trajectory_error:
                # å¦‚æœè½¨è¿¹è®°å½•å¤±è´¥ï¼Œè‡³å°‘è®°å½•åŸºæœ¬ä¿¡æ¯
                print(f"âš ï¸  {self.name}: è½¨è¿¹è®°å½•å¤±è´¥: {trajectory_error}")
                self.current_trajectory.append({
                    'state': state_key,
                    'action': (action_type, amount),
                    'game_state': {}
                })
            
            # è®°å½•åŠ¨ä½œé€‰æ‹©
            try:
                action_key = self._get_action_key(action_type, amount, game_state)
                self.action_count[state_key][action_key] += 1
            except Exception as action_key_error:
                print(f"âš ï¸  {self.name}: åŠ¨ä½œé”®è®°å½•å¤±è´¥: {action_key_error}")
                # ä½¿ç”¨é»˜è®¤åŠ¨ä½œé”®
                self.action_count[state_key]["default_action"] += 1
            
            return action_type, amount
            
        except Exception as e:
            # æ”¹è¿›é”™è¯¯ä¿¡æ¯æ˜¾ç¤º
            error_type = type(e).__name__
            error_msg = str(e)
            
            # å¦‚æœé”™è¯¯ä¿¡æ¯çœ‹èµ·æ¥åƒçŠ¶æ€é”®ï¼Œç®€åŒ–æ˜¾ç¤º
            if '_' in error_msg and len(error_msg.split('_')) >= 6:
                print(f"âš ï¸  {self.name}: å†…éƒ¨è®¡ç®—å¼‚å¸¸ (å·²è‡ªåŠ¨å¤„ç†)")
            else:
                print(f"âš ï¸  {self.name}: åŠ¨ä½œé€‰æ‹©å¼‚å¸¸ - {error_msg} (å·²è‡ªåŠ¨å¤„ç†)")
            
            # å‡ºç°é”™è¯¯æ—¶çš„å®‰å…¨å›é€€
            call_amount = game_state.get('call_amount', 0)
            
            # å°è¯•å®‰å…¨çš„é»˜è®¤åŠ¨ä½œ
            if call_amount == 0:
                return PlayerAction.CHECK, 0
            elif call_amount > 0 and self.chips >= call_amount:
                return PlayerAction.CALL, call_amount
            else:
                return PlayerAction.FOLD, 0
    
    def _should_explore(self, state_key: str) -> bool:
        """æ”¹è¿›çš„æ¢ç´¢å†³ç­–"""
        # åŸºç¡€Îµ-è´ªå©ª
        if random.random() < self.epsilon:
            return True
        
        # å¯¹æ–°çŠ¶æ€å¢åŠ æ¢ç´¢
        if self.state_visit_count[state_key] < 3:
            return True
        
        return False
    
    def _ucb_action_selection(self, state_key: str, available_actions: List[Tuple[PlayerAction, int]], 
                             game_state: Dict[str, Any]) -> Tuple[PlayerAction, int]:
        """UCBåŠ¨ä½œé€‰æ‹©"""
        try:
            best_action = None
            best_ucb = float('-inf')
            
            total_visits = sum(self.action_count[state_key].values())
            
            for action_type, amount in available_actions:
                action_key = self._get_action_key(action_type, amount, game_state)
                
                # Qå€¼ï¼ˆåŒQç½‘ç»œå¹³å‡ï¼‰
                q1 = self.q_table_1[state_key][action_key]
                q2 = self.q_table_2[state_key][action_key]
                q_value = (q1 + q2) / 2
                
                # UCBæ¢ç´¢å¥–åŠ±
                action_visits = self.action_count[state_key][action_key]
                if action_visits == 0:
                    ucb_bonus = float('inf')
                else:
                    ucb_bonus = math.sqrt(2 * math.log(total_visits + 1) / action_visits)
                
                ucb_value = q_value + 0.1 * ucb_bonus
                
                if ucb_value > best_ucb:
                    best_ucb = ucb_value
                    best_action = (action_type, amount)
            
            return best_action if best_action else random.choice(available_actions)
            
        except Exception as e:
            print(f"âš ï¸  {self.name} UCBé€‰æ‹©å‡ºç°é”™è¯¯: {e}, ä½¿ç”¨éšæœºé€‰æ‹©")
            return random.choice(available_actions) if available_actions else (PlayerAction.FOLD, 0)
    
    def _double_q_action_selection(self, state_key: str, available_actions: List[Tuple[PlayerAction, int]], 
                                  game_state: Dict[str, Any]) -> Tuple[PlayerAction, int]:
        """åŒQç½‘ç»œåŠ¨ä½œé€‰æ‹©"""
        try:
            best_action = None
            best_q = float('-inf')
            
            for action_type, amount in available_actions:
                action_key = self._get_action_key(action_type, amount, game_state)
                
                # åŒQç½‘ç»œçš„å¹³å‡Qå€¼
                q1 = self.q_table_1[state_key][action_key]
                q2 = self.q_table_2[state_key][action_key]
                avg_q = (q1 + q2) / 2
                
                if avg_q > best_q:
                    best_q = avg_q
                    best_action = (action_type, amount)
            
            return best_action if best_action else random.choice(available_actions)
            
        except Exception as e:
            print(f"âš ï¸  {self.name} åŒQé€‰æ‹©å‡ºç°é”™è¯¯: {e}, ä½¿ç”¨éšæœºé€‰æ‹©")
            return random.choice(available_actions) if available_actions else (PlayerAction.FOLD, 0)
    
    def _get_enhanced_actions(self, game_state: Dict[str, Any]) -> List[Tuple[PlayerAction, int]]:
        """è·å–å¢å¼ºçš„åŠ¨ä½œç©ºé—´"""
        try:
            actions = []
            call_amount = game_state.get('call_amount', 0)
            pot_size = game_state.get('pot', 1)
            min_raise = game_state.get('min_raise', game_state.get('big_blind', 20))
            
            # å¼ƒç‰Œï¼ˆé™¤éå·²ç»æ— éœ€è·Ÿæ³¨ï¼‰
            if call_amount > 0:
                actions.append((PlayerAction.FOLD, 0))
            
            # è¿‡ç‰Œæˆ–è·Ÿæ³¨
            if call_amount == 0:
                actions.append((PlayerAction.CHECK, 0))
            elif call_amount <= self.chips:
                actions.append((PlayerAction.CALL, call_amount))
            
            # å„ç§å¤§å°çš„åŠ æ³¨
            if self.chips > call_amount:
                remaining_chips = self.chips - call_amount
                
                # å°åŠ æ³¨ (0.3-0.5 pot)
                small_bet = max(min_raise, min(int(pot_size * 0.4), remaining_chips))
                if small_bet <= remaining_chips:
                    actions.append((PlayerAction.RAISE, call_amount + small_bet))
                
                # ä¸­ç­‰åŠ æ³¨ (0.6-0.8 pot)
                medium_bet = max(min_raise, min(int(pot_size * 0.7), remaining_chips))
                if medium_bet <= remaining_chips and medium_bet != small_bet:
                    actions.append((PlayerAction.RAISE, call_amount + medium_bet))
                
                # å¤§åŠ æ³¨ (1.0-1.5 pot)
                large_bet = max(min_raise, min(int(pot_size * 1.2), remaining_chips))
                if large_bet <= remaining_chips and large_bet != medium_bet:
                    actions.append((PlayerAction.RAISE, call_amount + large_bet))
                
                # å…¨æŠ¼
                if remaining_chips > min_raise:
                    actions.append((PlayerAction.ALL_IN, self.chips))
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªåŠ¨ä½œ
            if not actions:
                # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•åŠ¨ä½œï¼Œæ·»åŠ å®‰å…¨çš„é»˜è®¤åŠ¨ä½œ
                if call_amount == 0:
                    actions.append((PlayerAction.CHECK, 0))
                elif self.chips >= call_amount:
                    actions.append((PlayerAction.CALL, call_amount))
                else:
                    actions.append((PlayerAction.FOLD, 0))
            
            return actions
            
        except Exception as e:
            print(f"âš ï¸  {self.name} ç”ŸæˆåŠ¨ä½œå‡ºç°é”™è¯¯: {e}, ä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
            # å‡ºç°é”™è¯¯æ—¶çš„å®‰å…¨å›é€€
            call_amount = game_state.get('call_amount', 0)
            if call_amount == 0:
                return [(PlayerAction.CHECK, 0)]
            elif self.chips >= call_amount:
                return [(PlayerAction.CALL, call_amount)]
            else:
                return [(PlayerAction.FOLD, 0)]
    
    def _get_action_key(self, action_type: PlayerAction, amount: int, game_state: Dict[str, Any]) -> str:
        """è·å–åŠ¨ä½œé”®"""
        try:
            if action_type == PlayerAction.FOLD:
                return "fold"
            elif action_type == PlayerAction.CHECK:
                return "check"
            elif action_type == PlayerAction.CALL:
                return "call"
            elif action_type == PlayerAction.ALL_IN:
                return "all_in"
            else:  # RAISE
                pot_size = max(1, game_state.get('pot', 1))  # ç¡®ä¿è‡³å°‘ä¸º1
                call_amount = max(0, game_state.get('call_amount', 0))
                bet_size = max(0, amount - call_amount)
                
                if pot_size <= 0:
                    return "small_raise"  # é»˜è®¤è¿”å›
                
                bet_ratio = bet_size / pot_size
                
                if bet_ratio < 0.5:
                    return "small_raise"
                elif bet_ratio < 1.0:
                    return "medium_raise"
                else:
                    return "large_raise"
                    
        except (TypeError, ValueError, ZeroDivisionError):
            # å‡ºç°é”™è¯¯æ—¶è¿”å›é»˜è®¤åŠ¨ä½œé”®
            return "call"
    
    def learn_from_hand_result(self, hand_result: Dict[str, Any]):
        """ä»æ‰‹ç‰Œç»“æœä¸­å­¦ä¹ ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        if not self.current_trajectory:
            return
        
        # è®¡ç®—æ”¹è¿›çš„å¥–åŠ±
        reward = self._calculate_enhanced_reward(hand_result)
        
        # ç»éªŒå›æ”¾å­¦ä¹ 
        self._add_experience_and_learn(reward)
        
        # æ›´æ–°ç»Ÿè®¡
        self.total_reward += reward
        self.game_count += 1
        if hand_result.get('winner_id') == self.player_id:
            self.win_count += 1
        
        # è¡°å‡æ¢ç´¢ç‡
        self.decay_epsilon()
        
        # è®°å½•è®­ç»ƒè¿›åº¦ (æ¯Næ‰‹è®°å½•ä¸€æ¬¡)
        if (self.game_count - self.last_snapshot_game_count) >= self.snapshot_interval:
            self._record_training_progress()
            self.last_snapshot_game_count = self.game_count
        
        # æ¸…ç©ºå½“å‰è½¨è¿¹
        self.current_trajectory = []
    
    def _record_training_progress(self):
        """è®°å½•è®­ç»ƒè¿›åº¦åˆ°è¿½è¸ªå™¨"""
        try:
            from .training_tracker import TrainingTracker
            
            tracker = TrainingTracker()
            
            # ç¡®å®šæœºå™¨äººç±»å‹
            bot_type = 'improved_rl_bot'
            if hasattr(self, 'conservative_mode') and self.conservative_mode:
                bot_type = 'conservative_rl_bot'
            elif 'improved' not in self.model_path.lower():
                bot_type = 'rl_bot'
            
            # è·å–å½“å‰ç»Ÿè®¡
            current_stats = self.get_learning_stats()
            
            # æ·»åŠ é¢å¤–ä¿¡æ¯
            additional_info = {
                'snapshot_interval': self.snapshot_interval,
                'model_path': self.model_path,
                'current_chips': self.chips
            }
            
            # è®°å½•å¿«ç…§
            tracker.record_snapshot(bot_type, current_stats, additional_info)
            
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸å½±å“è®­ç»ƒ
            pass
    
    def _calculate_enhanced_reward(self, hand_result: Dict[str, Any]) -> float:
        """è®¡ç®—å¢å¼ºçš„å¥–åŠ±å‡½æ•°"""
        reward = 0.0
        
        # åŸºç¡€èƒœè´Ÿå¥–åŠ±
        if hand_result.get('winner_id') == self.player_id:
            winnings = hand_result.get('winnings', 0)
            # é™åˆ¶å¥–åŠ±çš„æœ€å¤§å€¼ï¼Œé˜²æ­¢æ•°å€¼æº¢å‡º
            roi_reward = winnings / max(self.total_bet_in_hand, 1)
            # ç¡®ä¿å¥–åŠ±æ˜¯æœ‰é™çš„ï¼Œå¹¶é™åˆ¶æœ€å¤§å€¼
            if math.isinf(roi_reward) or math.isnan(roi_reward) or roi_reward > 10.0:
                reward += 10.0  # è®¾ç½®æœ€å¤§å¥–åŠ±ä¸Šé™
            else:
                reward += min(10.0, roi_reward)  # ROIå¥–åŠ±ï¼Œé™åˆ¶åœ¨10.0ä»¥å†…
        else:
            # å¤±è´¥æƒ©ç½šï¼Œä½†ä¸è¿‡åº¦æƒ©ç½š
            reward -= min(1.0, self.total_bet_in_hand / max(self.chips + self.total_bet_in_hand, 1))
        
        # å†³ç­–è´¨é‡å¥–åŠ±
        for i, step in enumerate(self.current_trajectory):
            action_type, amount = step['action']
            game_state = step['game_state']
            
            # å¥–åŠ±åˆç†çš„ä¸‹æ³¨å¤§å°
            if action_type in [PlayerAction.RAISE, PlayerAction.CALL]:
                hand_strength = self.estimate_hand_strength(game_state)
                pot_odds = self.calculate_pot_odds(game_state)
                
                # å¼ºç‰Œæ—¶åŠ æ³¨è·å¾—å¥–åŠ±
                if hand_strength > 0.7 and action_type == PlayerAction.RAISE:
                    reward += 0.1
                
                # å¼±ç‰Œæ—¶å¼ƒç‰Œè·å¾—å¥–åŠ±
                elif hand_strength < 0.3 and action_type == PlayerAction.FOLD:
                    reward += 0.05
                
                # åˆç†çš„åº•æ± èµ”ç‡å†³ç­–
                if pot_odds > 3 and hand_strength > 0.4 and action_type == PlayerAction.CALL:
                    reward += 0.05
        
        # ç”Ÿå­˜å¥–åŠ±ï¼ˆé¿å…è¿‡æ—©å…¨æŠ¼ï¼‰
        if not self.is_folded and self.chips > 0:
            reward += 0.02
        
        return reward
    
    def _add_experience_and_learn(self, final_reward: float):
        """æ·»åŠ ç»éªŒå¹¶è¿›è¡Œå­¦ä¹ """
        # è®¡ç®—æ¯æ­¥çš„å¥–åŠ±ï¼ˆæ—¶é—´å·®åˆ†ï¼‰
        for i, step in enumerate(self.current_trajectory):
            state = step['state']
            action_type, amount = step['action']
            action_key = self._get_action_key(action_type, amount, step['game_state'])
            
            # è®¡ç®—æŠ˜æ‰£å¥–åŠ±
            steps_to_end = len(self.current_trajectory) - i - 1
            discounted_reward = final_reward * (self.discount_factor ** steps_to_end)
            
            # æ·»åŠ åˆ°ç»éªŒç¼“å†²
            experience = {
                'state': state,
                'action': action_key,
                'reward': discounted_reward,
                'next_state': self.current_trajectory[i+1]['state'] if i+1 < len(self.current_trajectory) else None
            }
            self.experience_buffer.append(experience)
        
        # ç»éªŒå›æ”¾å­¦ä¹ 
        self._replay_experience()
    
    def _replay_experience(self):
        """ç»éªŒå›æ”¾å­¦ä¹ """
        if len(self.experience_buffer) < self.batch_size:
            return
        
        # éšæœºé‡‡æ ·ç»éªŒ
        batch = random.sample(self.experience_buffer, min(self.batch_size, len(self.experience_buffer)))
        
        for experience in batch:
            state = experience['state']
            action = experience['action']
            reward = experience['reward']
            next_state = experience['next_state']
            
            # åŒQå­¦ä¹ æ›´æ–°
            if random.random() < 0.5:
                self._update_q_table(self.q_table_1, self.q_table_2, state, action, reward, next_state)
            else:
                self._update_q_table(self.q_table_2, self.q_table_1, state, action, reward, next_state)
    
    def _update_q_table(self, primary_q: dict, secondary_q: dict, state: str, action: str, 
                       reward: float, next_state: str):
        """æ›´æ–°Qè¡¨ï¼ˆåŒQå­¦ä¹ ï¼‰"""
        current_q = primary_q[state][action]
        
        if next_state:
            # ä½¿ç”¨primary_qé€‰æ‹©åŠ¨ä½œï¼Œsecondary_qè¯„ä¼°ä»·å€¼
            best_next_action = max(primary_q[next_state].items(), 
                                 key=lambda x: x[1], default=(None, 0))[0]
            if best_next_action:
                max_next_q = secondary_q[next_state][best_next_action]
            else:
                max_next_q = 0
        else:
            max_next_q = 0
        
        # Qå­¦ä¹ æ›´æ–°
        target_q = reward + self.discount_factor * max_next_q
        new_q = current_q + self.learning_rate * (target_q - current_q)
        primary_q[state][action] = new_q
    
    def decay_epsilon(self):
        """è¡°å‡æ¢ç´¢ç‡"""
        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)
    
    def estimate_hand_strength(self, game_state: Dict[str, Any]) -> float:
        """è¯„ä¼°æ‰‹ç‰Œå¼ºåº¦ï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰"""
        community_cards = game_state.get('community_cards', [])
        
        # è½¬æ¢å­—ç¬¦ä¸²æ ¼å¼çš„ç‰Œ
        if community_cards and isinstance(community_cards[0], str):
            card_objects = []
            for card_str in community_cards:
                try:
                    card_objects.append(Card.from_string(card_str))
                except:
                    continue
            community_cards = card_objects
        
        all_cards = self.hole_cards + community_cards
        
        # ä½¿ç”¨HandEvaluatoræˆ–ç®€åŒ–è¯„ä¼°
        if len(all_cards) == 5 or len(all_cards) == 7:
            return HandEvaluator.get_hand_strength(all_cards)
        elif len(all_cards) >= 3:
            return self._evaluate_partial_hand_strength(all_cards)
        else:
            return self._evaluate_preflop_strength()
    
    def _evaluate_preflop_strength(self) -> float:
        """è¯„ä¼°ç¿»ç‰Œå‰æ‰‹ç‰Œå¼ºåº¦"""
        if len(self.hole_cards) != 2:
            return 0.0
        
        card1, card2 = self.hole_cards
        
        # å£è¢‹å¯¹å­
        if card1.rank_value == card2.rank_value:
            if card1.rank_value >= 10:
                return 0.9
            elif card1.rank_value >= 7:
                return 0.7
            else:
                return 0.5
        
        # åŒèŠ±è¿å¼ 
        if card1.suit == card2.suit:
            if abs(card1.rank_value - card2.rank_value) == 1:
                return 0.8
        
        # é«˜ç‰Œç»„åˆ
        high_card = max(card1.rank_value, card2.rank_value)
        low_card = min(card1.rank_value, card2.rank_value)
        
        if high_card == 14:  # A
            if low_card >= 11:
                return 0.85
            elif low_card >= 9:
                return 0.6
            else:
                return 0.4
        elif high_card >= 13:  # K, Q
            if low_card >= 11:
                return 0.7
            elif low_card >= 9:
                return 0.5
            else:
                return 0.3
        
        return 0.2
    
    def _evaluate_partial_hand_strength(self, all_cards) -> float:
        """è¯„ä¼°éƒ¨åˆ†æ‰‹ç‰Œå¼ºåº¦"""
        if len(all_cards) < 3:
            return self._evaluate_preflop_strength()
        
        from collections import Counter
        values = [card.rank_value for card in all_cards]
        suits = [card.suit for card in all_cards]
        
        value_counts = Counter(values)
        suit_counts = Counter(suits)
        
        base_score = 0.3
        
        # æ£€æŸ¥æˆç‰Œ
        counts = sorted(value_counts.values(), reverse=True)
        if counts[0] >= 3:
            base_score = 0.8
        elif counts[0] == 2:
            pair_value = max([v for v, c in value_counts.items() if c == 2])
            if pair_value >= 10:
                base_score = 0.6
            else:
                base_score = 0.5
        
        # åŒèŠ±å¯èƒ½æ€§
        max_suit_count = max(suit_counts.values())
        if max_suit_count >= 3:
            base_score += 0.1
        
        # é¡ºå­å¯èƒ½æ€§
        unique_values = sorted(set(values))
        if len(unique_values) >= 3:
            consecutive_count = 1
            max_consecutive = 1
            for i in range(1, len(unique_values)):
                if unique_values[i] - unique_values[i-1] == 1:
                    consecutive_count += 1
                    max_consecutive = max(max_consecutive, consecutive_count)
                else:
                    consecutive_count = 1
            
            if max_consecutive >= 3:
                base_score += 0.1
        
        return min(0.9, base_score)
    
    def calculate_pot_odds(self, game_state: Dict[str, Any]) -> float:
        """è®¡ç®—åº•æ± èµ”ç‡"""
        try:
            call_amount = game_state.get('call_amount', 0)
            pot_size = game_state.get('pot', 0)
            
            if call_amount <= 0:
                return float('inf')
            
            if pot_size <= 0:
                return 0.0
            
            return pot_size / call_amount
            
        except (ZeroDivisionError, TypeError, ValueError):
            # è®¡ç®—å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
            return 2.0  # é»˜è®¤çš„åˆç†åº•æ± èµ”ç‡
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        total_states = len(self.q_table_1) + len(self.q_table_2)
        total_state_actions = sum(len(actions) for actions in self.q_table_1.values())
        total_state_actions += sum(len(actions) for actions in self.q_table_2.values())
        
        return {
            'q_table_size': total_states // 2,  # åŒQç½‘ç»œï¼Œé™¤ä»¥2
            'total_states': total_state_actions // 2,
            'epsilon': self.epsilon,
            'memory_size': len(self.experience_buffer),
            'total_reward': self.total_reward,
            'game_count': self.game_count,
            'win_rate': self.win_count / max(1, self.game_count),
            'avg_reward': self.total_reward / max(1, self.game_count)
        } 