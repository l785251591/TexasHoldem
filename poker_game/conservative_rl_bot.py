#!/usr/bin/env python3
"""
ä¿å®ˆç‰ˆå¼ºåŒ–å­¦ä¹ æœºå™¨äºº
é’ˆå¯¹è®­ç»ƒåˆæœŸä¼˜åŒ–ï¼Œå‡å°‘ç­¹ç æŸå¤±
"""

from .improved_rl_bot import ImprovedRLBot
from .player import PlayerAction
from typing import Dict, Any, Tuple, List
import random
import math

class ConservativeRLBot(ImprovedRLBot):
    """ä¿å®ˆç‰ˆå¼ºåŒ–å­¦ä¹ æœºå™¨äººï¼Œé€‚åˆè®­ç»ƒåˆæœŸä½¿ç”¨"""
    
    def __init__(self, player_id: str, name: str, chips: int = 1000, 
                 model_path: str = "models/conservative_rl_bot_model.pkl"):
        super().__init__(player_id, name, chips, model_path)
        
        # è°ƒæ•´åçš„å­¦ä¹ å‚æ•°ï¼šæ›´å¹³è¡¡çš„ä¿å®ˆç­–ç•¥
        self.epsilon = 0.15         # é€‚ä¸­çš„æ¢ç´¢ç‡ (ä»0.1åˆ°0.15)
        self.epsilon_decay = 0.9998 # é€‚ä¸­çš„è¡°å‡ (ä»0.999åˆ°0.9998)
        self.epsilon_min = 0.03     # ä¿æŒé€‚åº¦æ¢ç´¢ (ä»0.02åˆ°0.03)
        self.learning_rate = 0.008  # ç¨å¾®æé«˜å­¦ä¹ ç‡ (ä»0.005åˆ°0.008)
        
        # è°ƒæ•´åçš„ä¿å®ˆç­–ç•¥å‚æ•°
        self.conservative_mode = True
        self.aggression_threshold = 0.6  # é™ä½æ¿€è¿›é˜ˆå€¼ (ä»0.8åˆ°0.6)
        self.max_bet_ratio = 0.3         # å¢åŠ æœ€å¤§ä¸‹æ³¨æ¯”ä¾‹ (ä»0.2åˆ°0.3)
        self.min_hand_strength_call = 0.2  # é™ä½è·Ÿæ³¨é˜ˆå€¼ (ä»0.3åˆ°0.2)
        self.min_hand_strength_raise = 0.65  # æ–°å¢ï¼šåŠ æ³¨é˜ˆå€¼
        self.all_in_threshold = 0.85     # é™ä½å…¨æŠ¼é˜ˆå€¼ (ä»0.95åˆ°0.85)
        
    def _get_enhanced_actions(self, game_state: Dict[str, Any]) -> List[Tuple[PlayerAction, int]]:
        """è·å–ä¿å®ˆçš„åŠ¨ä½œç©ºé—´"""
        if not self.conservative_mode:
            return super()._get_enhanced_actions(game_state)
        
        try:
            actions = []
            call_amount = game_state.get('call_amount', 0)
            pot_size = max(1, game_state.get('pot', 1))
            min_raise = game_state.get('min_raise', game_state.get('big_blind', 20))
            
            # è¯„ä¼°æ‰‹ç‰Œå¼ºåº¦
            hand_strength = self.estimate_hand_strength(game_state)
            
            # å¼ƒç‰Œ (æ€»æ˜¯å¯ç”¨)
            if call_amount > 0:
                actions.append((PlayerAction.FOLD, 0))
            
            # è¿‡ç‰Œæˆ–è·Ÿæ³¨
            if call_amount == 0:
                actions.append((PlayerAction.CHECK, 0))
            elif call_amount <= self.chips:
                # ä¿å®ˆçš„è·Ÿæ³¨ç­–ç•¥ï¼šåªæœ‰åœ¨åˆç†æƒ…å†µä¸‹æ‰è·Ÿæ³¨
                pot_odds = pot_size / call_amount if call_amount > 0 else float('inf')
                if hand_strength > self.min_hand_strength_call or pot_odds > 3:  # æ‰‹ç‰Œä¸é”™æˆ–èµ”ç‡å¥½
                    actions.append((PlayerAction.CALL, call_amount))
            
            # ä¿å®ˆçš„åŠ æ³¨ç­–ç•¥
            if self.chips > call_amount and hand_strength > self.aggression_threshold:
                remaining_chips = self.chips - call_amount
                max_bet = min(int(self.chips * self.max_bet_ratio), remaining_chips)
                
                # åªåœ¨æ‰‹ç‰Œå¾ˆå¼ºæ—¶æ‰åŠ æ³¨
                if max_bet >= min_raise:
                    # å°åŠ æ³¨
                    small_bet = max(min_raise, min(int(pot_size * 0.3), max_bet))
                    if small_bet <= remaining_chips:
                        actions.append((PlayerAction.RAISE, call_amount + small_bet))
                    
                    # ä¸­ç­‰åŠ æ³¨ (åªæœ‰åœ¨æ‰‹ç‰Œç‰¹åˆ«å¼ºæ—¶)
                    if hand_strength > self.min_hand_strength_raise:
                        medium_bet = max(min_raise, min(int(pot_size * 0.5), max_bet))
                        if medium_bet <= remaining_chips and medium_bet != small_bet:
                            actions.append((PlayerAction.RAISE, call_amount + medium_bet))
            
            # ç§»é™¤å…¨æŠ¼é€‰é¡¹ (å¤ªå±é™©)
            # åªåœ¨ç»å¯¹ç¡®å®šæ—¶æ‰å…¨æŠ¼
            if hand_strength > self.all_in_threshold and self.chips <= pot_size:
                actions.append((PlayerAction.ALL_IN, self.chips))
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªåŠ¨ä½œ
            if not actions:
                if call_amount == 0:
                    actions.append((PlayerAction.CHECK, 0))
                elif self.chips >= call_amount:
                    actions.append((PlayerAction.CALL, call_amount))
                else:
                    actions.append((PlayerAction.FOLD, 0))
            
            return actions
            
        except Exception as e:
            print(f"âš ï¸  {self.name} ä¿å®ˆåŠ¨ä½œç”Ÿæˆå¤±è´¥: {e}")
            # å®‰å…¨å›é€€
            call_amount = game_state.get('call_amount', 0)
            if call_amount == 0:
                return [(PlayerAction.CHECK, 0)]
            elif self.chips >= call_amount:
                return [(PlayerAction.CALL, call_amount)]
            else:
                return [(PlayerAction.FOLD, 0)]
    
    def _should_explore(self, state_key: str) -> bool:
        """æ›´ä¿å®ˆçš„æ¢ç´¢ç­–ç•¥"""
        # åŸºç¡€Îµ-è´ªå©ªï¼Œä½†æ¢ç´¢ç‡æ›´ä½
        if random.random() < self.epsilon:
            return True
        
        # å¯¹æ–°çŠ¶æ€çš„æ¢ç´¢æ›´è°¨æ…
        if self.state_visit_count[state_key] < 2:  # é™ä½ä»3åˆ°2
            return True
        
        return False
    
    def _calculate_enhanced_reward(self, hand_result: Dict[str, Any]) -> float:
        """æ›´å¹³è¡¡çš„å¥–åŠ±å‡½æ•°"""
        reward = 0.0
        
        # åŸºç¡€èƒœè´Ÿå¥–åŠ±
        if hand_result.get('winner_id') == self.player_id:
            winnings = hand_result.get('winnings', 0)
            # é€‚åº¦é¼“åŠ±èƒœåˆ©ï¼Œä½†é™åˆ¶è¿‡åº¦å¥–åŠ±
            roi_reward = winnings / max(self.total_bet_in_hand, 1)
            # é˜²æ­¢æ•°å€¼æº¢å‡ºå¹¶é™åˆ¶å¥–åŠ±èŒƒå›´
            if math.isinf(roi_reward) or math.isnan(roi_reward) or roi_reward > 5.0:
                reward += 5.0  # è®¾ç½®åˆç†ä¸Šé™
            else:
                reward += min(5.0, roi_reward)
        else:
            # å¯¹å¤±è´¥çš„æƒ©ç½šæ›´æ¸©å’Œï¼Œé¼“åŠ±é€‚åº¦å†’é™©
            loss_ratio = self.total_bet_in_hand / max(self.chips + self.total_bet_in_hand, 1)
            reward -= min(1.5, loss_ratio * 1.0)  # é€‚åº¦æƒ©ç½š
        
        # ç”Ÿå­˜å¥–åŠ±
        if not self.is_folded and self.chips > 0:
            reward += 0.15  # å¢åŠ ç”Ÿå­˜å¥–åŠ±
        
        # ç­–ç•¥å¹³è¡¡å¥–åŠ±
        for i, step in enumerate(self.current_trajectory):
            action_type, amount = step['action']
            game_state = step['game_state']
            hand_strength = self.estimate_hand_strength(game_state)
            
            # é¼“åŠ±åˆç†çš„å¼ƒç‰Œ
            if action_type == PlayerAction.FOLD:
                if hand_strength < 0.3:  # å¼±ç‰Œå¼ƒç‰Œ
                    reward += 0.1
                elif hand_strength > 0.7:  # å¼ºç‰Œå¼ƒç‰Œè½»å¾®æƒ©ç½š
                    reward -= 0.05
            
            # é¼“åŠ±åˆç†çš„è·Ÿæ³¨å’ŒåŠ æ³¨
            elif action_type in [PlayerAction.CALL, PlayerAction.RAISE]:
                bet_ratio = amount / max(self.chips, 1)
                
                # æ ¹æ®æ‰‹ç‰Œå¼ºåº¦è¯„ä¼°ä¸‹æ³¨åˆç†æ€§
                if hand_strength > 0.6:  # å¼ºç‰Œ
                    if bet_ratio > 0.1:  # é¼“åŠ±å¼ºç‰Œä¸‹æ³¨
                        reward += 0.08
                elif hand_strength > 0.4:  # ä¸­ç­‰æ‰‹ç‰Œ
                    if 0.05 <= bet_ratio <= 0.3:  # é¼“åŠ±é€‚åº¦ä¸‹æ³¨
                        reward += 0.05
                else:  # å¼±ç‰Œ
                    if bet_ratio < 0.15:  # å¼±ç‰Œå°æ³¨å¯ä»¥æ¥å—
                        reward += 0.02
                    else:  # å¼±ç‰Œå¤§æ³¨æƒ©ç½š
                        reward -= 0.08
            
            # è¯„ä¼°å…¨æŠ¼å†³ç­–
            elif action_type == PlayerAction.ALL_IN:
                if hand_strength > 0.8:  # å¼ºç‰Œå…¨æŠ¼å¥–åŠ±
                    reward += 0.1
                elif hand_strength < 0.4:  # å¼±ç‰Œå…¨æŠ¼ä¸¥é‡æƒ©ç½š
                    reward -= 0.3
                else:  # ä¸­ç­‰ç‰Œå…¨æŠ¼è½»å¾®æƒ©ç½š
                    reward -= 0.1
        
        # é™åˆ¶æ€»å¥–åŠ±èŒƒå›´ï¼Œé˜²æ­¢è¿‡åº¦å¥–åŠ±æˆ–æƒ©ç½š
        return max(-3.0, min(10.0, reward))
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¿å®ˆç‰ˆï¼‰"""
        stats = super().get_learning_stats()
        stats.update({
            'conservative_mode': self.conservative_mode,
            'aggression_threshold': self.aggression_threshold,
            'max_bet_ratio': self.max_bet_ratio,
            'min_hand_strength_call': self.min_hand_strength_call,
            'min_hand_strength_raise': self.min_hand_strength_raise,
            'all_in_threshold': self.all_in_threshold,
            'bot_type': 'Conservative'
        })
        return stats
    
    def enable_normal_mode(self):
        """åˆ‡æ¢åˆ°æ­£å¸¸æ¨¡å¼ï¼ˆè®­ç»ƒåæœŸä½¿ç”¨ï¼‰"""
        self.conservative_mode = False
        self.epsilon = min(0.2, self.epsilon * 2)  # ç¨å¾®æé«˜æ¢ç´¢ç‡
        self.aggression_threshold = 0.6  # é™ä½æ¿€è¿›é˜ˆå€¼
        self.max_bet_ratio = 0.5  # å¢åŠ æœ€å¤§ä¸‹æ³¨æ¯”ä¾‹
        print(f"ğŸš€ {self.name} åˆ‡æ¢åˆ°æ­£å¸¸æ¨¡å¼")
    
    def auto_adjust_conservatism(self):
        """æ ¹æ®è¡¨ç°è‡ªåŠ¨è°ƒæ•´ä¿å®ˆç¨‹åº¦"""
        if self.game_count > 100:
            win_rate = self.win_count / self.game_count
            
            # å¦‚æœè¡¨ç°å¾ˆå¥½ï¼Œé€æ¸å‡å°‘ä¿å®ˆç¨‹åº¦
            if win_rate > 0.3:
                self.aggression_threshold = max(0.6, self.aggression_threshold - 0.01)
                self.max_bet_ratio = min(0.5, self.max_bet_ratio + 0.01)
            # å¦‚æœè¡¨ç°å¾ˆå·®ï¼Œå¢åŠ ä¿å®ˆç¨‹åº¦
            elif win_rate < 0.1:
                self.aggression_threshold = min(0.9, self.aggression_threshold + 0.01)
                self.max_bet_ratio = max(0.1, self.max_bet_ratio - 0.01)
    
    def learn_from_hand_result(self, hand_result: Dict[str, Any]):
        """å­¦ä¹ æ—¶è‡ªåŠ¨è°ƒæ•´ä¿å®ˆç¨‹åº¦"""
        super().learn_from_hand_result(hand_result)
        
        # æ¯100æ‰‹è‡ªåŠ¨è°ƒæ•´ä¸€æ¬¡
        if self.game_count % 100 == 0:
            self.auto_adjust_conservatism()
    
    def _record_training_progress(self):
        """è®°å½•è®­ç»ƒè¿›åº¦åˆ°è¿½è¸ªå™¨ï¼ˆä¿å®ˆç‰ˆä¸“ç”¨ï¼‰"""
        try:
            from .training_tracker import TrainingTracker
            
            tracker = TrainingTracker()
            
            # è·å–å½“å‰ç»Ÿè®¡
            current_stats = self.get_learning_stats()
            
            # æ·»åŠ é¢å¤–ä¿¡æ¯
            additional_info = {
                'snapshot_interval': self.snapshot_interval,
                'model_path': self.model_path,
                'current_chips': self.chips,
                'conservative_mode': self.conservative_mode,
                'aggression_threshold': self.aggression_threshold,
                'max_bet_ratio': self.max_bet_ratio,
                'min_hand_strength_call': self.min_hand_strength_call,
                'min_hand_strength_raise': self.min_hand_strength_raise,
                'all_in_threshold': self.all_in_threshold
            }
            
            # è®°å½•å¿«ç…§ - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æœºå™¨äººç±»å‹
            tracker.record_snapshot('conservative_rl_bot', current_stats, additional_info)
            
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸å½±å“è®­ç»ƒ
            pass 