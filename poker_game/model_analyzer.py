#!/usr/bin/env python3
"""
å¼ºåŒ–å­¦ä¹ æ¨¡å‹åˆ†æå·¥å…·
åˆ†ææ¨¡å‹æ–‡ä»¶å¤§å°å˜åŒ–åŸå› å’Œå­¦ä¹ æ•ˆç‡
"""

import pickle
import os
import sys
from typing import Dict, Any, List, Tuple
import matplotlib.pyplot as plt
from collections import defaultdict
import json

class ModelAnalyzer:
    """æ¨¡å‹åˆ†æå™¨"""
    
    def __init__(self):
        self.analysis_data = []
    
    def analyze_model_file(self, model_path: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ¨¡å‹æ–‡ä»¶"""
        if not os.path.exists(model_path):
            return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"}
        
        try:
            # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            file_size = os.path.getsize(model_path)
            
            # åŠ è½½æ¨¡å‹æ•°æ®
            with open(model_path, 'rb') as f:
                data = pickle.load(f)
            
            # åˆ†æå„ç»„ä»¶å¤§å°
            analysis = {
                "file_path": model_path,
                "total_file_size": file_size,
                "components": {},
                "learning_metrics": {},
                "efficiency_metrics": {}
            }
            
            # åˆ†æå„ä¸ªç»„ä»¶çš„å¤§å°
            for key, value in data.items():
                component_size = sys.getsizeof(pickle.dumps(value))
                analysis["components"][key] = {
                    "size_bytes": component_size,
                    "size_percentage": (component_size / file_size) * 100
                }
            
            # åˆ†æQè¡¨è¯¦ç»†ä¿¡æ¯
            if 'q_table' in data:
                q_table = data['q_table']
                analysis["q_table_stats"] = self._analyze_q_table(q_table, "single")
            elif 'q_table_1' in data and 'q_table_2' in data:
                q_table_1 = data['q_table_1']
                q_table_2 = data['q_table_2']
                analysis["q_table_stats"] = {
                    "q_table_1": self._analyze_q_table(q_table_1, "double_1"),
                    "q_table_2": self._analyze_q_table(q_table_2, "double_2"),
                    "combined": self._analyze_combined_q_tables(q_table_1, q_table_2)
                }
            
            # å­¦ä¹ æŒ‡æ ‡
            analysis["learning_metrics"] = {
                "game_count": data.get('game_count', 0),
                "win_count": data.get('win_count', 0),
                "win_rate": data.get('win_count', 0) / max(1, data.get('game_count', 1)) * 100,
                "total_reward": data.get('total_reward', 0),
                "avg_reward": data.get('total_reward', 0) / max(1, data.get('game_count', 1)),
                "current_epsilon": data.get('epsilon', 0)
            }
            
            # æ•ˆç‡æŒ‡æ ‡
            analysis["efficiency_metrics"] = self._calculate_efficiency_metrics(data)
            
            return analysis
            
        except Exception as e:
            return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    def _analyze_q_table(self, q_table: Dict, table_type: str) -> Dict[str, Any]:
        """åˆ†æQè¡¨ç»“æ„"""
        total_states = len(q_table)
        total_state_action_pairs = 0
        action_distribution = defaultdict(int)
        value_distribution = {'positive': 0, 'negative': 0, 'zero': 0}
        
        for state, actions in q_table.items():
            total_state_action_pairs += len(actions)
            for action, value in actions.items():
                action_distribution[action] += 1
                if value > 0.001:
                    value_distribution['positive'] += 1
                elif value < -0.001:
                    value_distribution['negative'] += 1
                else:
                    value_distribution['zero'] += 1
        
        avg_actions_per_state = total_state_action_pairs / max(1, total_states)
        
        return {
            "table_type": table_type,
            "total_states": total_states,
            "total_state_action_pairs": total_state_action_pairs,
            "avg_actions_per_state": avg_actions_per_state,
            "action_distribution": dict(action_distribution),
            "value_distribution": dict(value_distribution),
            "memory_usage_estimation": total_state_action_pairs * 64  # ä¼°ç®—å­—èŠ‚æ•°
        }
    
    def _analyze_combined_q_tables(self, q_table_1: Dict, q_table_2: Dict) -> Dict[str, Any]:
        """åˆ†æåŒQè¡¨çš„ç»„åˆä¿¡æ¯"""
        all_states = set(q_table_1.keys()) | set(q_table_2.keys())
        common_states = set(q_table_1.keys()) & set(q_table_2.keys())
        
        return {
            "total_unique_states": len(all_states),
            "common_states": len(common_states),
            "state_overlap_percentage": len(common_states) / len(all_states) * 100 if all_states else 0,
            "q1_only_states": len(set(q_table_1.keys()) - set(q_table_2.keys())),
            "q2_only_states": len(set(q_table_2.keys()) - set(q_table_1.keys()))
        }
    
    def _calculate_efficiency_metrics(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—å­¦ä¹ æ•ˆç‡æŒ‡æ ‡"""
        game_count = data.get('game_count', 0)
        win_count = data.get('win_count', 0)
        
        # Qè¡¨å¤§å°ç›¸å…³
        if 'q_table' in data:
            total_states = len(data['q_table'])
            total_entries = sum(len(actions) for actions in data['q_table'].values())
        elif 'q_table_1' in data:
            total_states = len(set(data['q_table_1'].keys()) | set(data.get('q_table_2', {}).keys()))
            total_entries = (sum(len(actions) for actions in data['q_table_1'].values()) + 
                           sum(len(actions) for actions in data.get('q_table_2', {}).values()))
        else:
            total_states = 0
            total_entries = 0
        
        # çŠ¶æ€è®¿é—®ç»Ÿè®¡
        state_visits = data.get('state_visit_count', {})
        total_state_visits = sum(state_visits.values()) if state_visits else 0
        
        # æ•ˆç‡æŒ‡æ ‡
        metrics = {
            "states_per_game": total_states / max(1, game_count),
            "entries_per_game": total_entries / max(1, game_count),
            "avg_state_visits": total_state_visits / max(1, total_states),
            "learning_density": total_entries / max(1, total_state_visits),  # æ¯æ¬¡è®¿é—®äº§ç”Ÿçš„Qå€¼æ•°
            "exploration_efficiency": total_states / max(1, total_state_visits),  # æ¢ç´¢æ•ˆç‡
            "win_rate_per_1000_states": (win_count / max(1, game_count)) * 1000 / max(1, total_states)
        }
        
        return metrics
    
    def compare_model_snapshots(self, model_paths: List[str]) -> Dict[str, Any]:
        """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹å¿«ç…§ï¼Œåˆ†æå¢é•¿è¶‹åŠ¿"""
        analyses = []
        
        for path in sorted(model_paths):
            analysis = self.analyze_model_file(path)
            if "error" not in analysis:
                analyses.append(analysis)
        
        if len(analyses) < 2:
            return {"error": "éœ€è¦è‡³å°‘2ä¸ªæœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œæ¯”è¾ƒ"}
        
        # è¶‹åŠ¿åˆ†æ
        trends = {
            "file_size_trend": [],
            "q_table_growth": [],
            "learning_progress": [],
            "efficiency_trend": []
        }
        
        for i, analysis in enumerate(analyses):
            trends["file_size_trend"].append({
                "index": i,
                "size": analysis["total_file_size"],
                "game_count": analysis["learning_metrics"]["game_count"]
            })
            
            if "q_table_stats" in analysis:
                if "total_states" in analysis["q_table_stats"]:
                    # å•Qè¡¨
                    states = analysis["q_table_stats"]["total_states"]
                    entries = analysis["q_table_stats"]["total_state_action_pairs"]
                else:
                    # åŒQè¡¨
                    states = analysis["q_table_stats"]["combined"]["total_unique_states"]
                    entries = (analysis["q_table_stats"]["q_table_1"]["total_state_action_pairs"] + 
                             analysis["q_table_stats"]["q_table_2"]["total_state_action_pairs"])
                
                trends["q_table_growth"].append({
                    "index": i,
                    "states": states,
                    "entries": entries,
                    "game_count": analysis["learning_metrics"]["game_count"]
                })
            
            trends["learning_progress"].append({
                "index": i,
                "win_rate": analysis["learning_metrics"]["win_rate"],
                "avg_reward": analysis["learning_metrics"]["avg_reward"],
                "epsilon": analysis["learning_metrics"]["current_epsilon"],
                "game_count": analysis["learning_metrics"]["game_count"]
            })
            
            trends["efficiency_trend"].append({
                "index": i,
                "states_per_game": analysis["efficiency_metrics"]["states_per_game"],
                "exploration_efficiency": analysis["efficiency_metrics"]["exploration_efficiency"],
                "game_count": analysis["learning_metrics"]["game_count"]
            })
        
        # è®¡ç®—å¢é•¿ç‡
        growth_analysis = self._analyze_growth_patterns(trends)
        
        return {
            "total_snapshots": len(analyses),
            "trends": trends,
            "growth_analysis": growth_analysis,
            "recommendations": self._generate_recommendations(growth_analysis)
        }
    
    def _analyze_growth_patterns(self, trends: Dict[str, List]) -> Dict[str, Any]:
        """åˆ†æå¢é•¿æ¨¡å¼"""
        analysis = {}
        
        # æ–‡ä»¶å¤§å°å¢é•¿ç‡
        if len(trends["file_size_trend"]) >= 2:
            sizes = [item["size"] for item in trends["file_size_trend"]]
            games = [item["game_count"] for item in trends["file_size_trend"]]
            
            early_growth = (sizes[len(sizes)//3] - sizes[0]) / max(1, games[len(games)//3] - games[0])
            late_growth = (sizes[-1] - sizes[2*len(sizes)//3]) / max(1, games[-1] - games[2*len(games)//3])
            
            analysis["file_size_growth"] = {
                "early_growth_rate": early_growth,
                "late_growth_rate": late_growth,
                "growth_deceleration": (early_growth - late_growth) / max(1, early_growth) * 100,
                "total_growth": sizes[-1] - sizes[0]
            }
        
        # Qè¡¨å¢é•¿ç‡
        if len(trends["q_table_growth"]) >= 2:
            states = [item["states"] for item in trends["q_table_growth"]]
            games = [item["game_count"] for item in trends["q_table_growth"]]
            
            early_state_growth = (states[len(states)//3] - states[0]) / max(1, games[len(games)//3] - games[0])
            late_state_growth = (states[-1] - states[2*len(states)//3]) / max(1, games[-1] - games[2*len(games)//3])
            
            analysis["q_table_growth"] = {
                "early_state_growth_rate": early_state_growth,
                "late_state_growth_rate": late_state_growth,
                "state_growth_deceleration": (early_state_growth - late_state_growth) / max(1, early_state_growth) * 100,
                "total_states": states[-1] - states[0]
            }
        
        # å­¦ä¹ æ•ˆç‡
        if len(trends["learning_progress"]) >= 2:
            win_rates = [item["win_rate"] for item in trends["learning_progress"]]
            epsilons = [item["epsilon"] for item in trends["learning_progress"]]
            
            analysis["learning_efficiency"] = {
                "win_rate_improvement": win_rates[-1] - win_rates[0],
                "epsilon_decay": epsilons[0] - epsilons[-1],
                "learning_stability": self._calculate_stability(win_rates)
            }
        
        return analysis
    
    def _calculate_stability(self, values: List[float]) -> float:
        """è®¡ç®—æ•°å€¼åºåˆ—çš„ç¨³å®šæ€§ï¼ˆå˜å¼‚ç³»æ•°çš„å€’æ•°ï¼‰"""
        if len(values) < 2:
            return 0
        
        mean_val = sum(values) / len(values)
        variance = sum((x - mean_val) ** 2 for x in values) / len(values)
        std_dev = variance ** 0.5
        
        if mean_val == 0:
            return 0
        
        cv = std_dev / abs(mean_val)  # å˜å¼‚ç³»æ•°
        return 1 / (1 + cv)  # ç¨³å®šæ€§æŒ‡æ ‡
    
    def _generate_recommendations(self, growth_analysis: Dict[str, Any]) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # æ–‡ä»¶å¢é•¿å»ºè®®
        if "file_size_growth" in growth_analysis:
            growth_data = growth_analysis["file_size_growth"]
            if growth_data["growth_deceleration"] > 50:
                recommendations.append(
                    "âœ… æ–‡ä»¶å¤§å°å¢é•¿æ”¾ç¼“æ˜¯æ­£å¸¸ç°è±¡ï¼Œè¡¨æ˜æ¨¡å‹è¶‹äºæ”¶æ•›"
                )
            elif growth_data["growth_deceleration"] < 10:
                recommendations.append(
                    "âš ï¸ æ–‡ä»¶ä»åœ¨å¿«é€Ÿå¢é•¿ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´æ¥æ”¶æ•›"
                )
        
        # Qè¡¨å¢é•¿å»ºè®®
        if "q_table_growth" in growth_analysis:
            q_data = growth_analysis["q_table_growth"]
            if q_data["state_growth_deceleration"] > 60:
                recommendations.append(
                    "âœ… Qè¡¨çŠ¶æ€å¢é•¿æ”¾ç¼“ï¼Œæ¨¡å‹å·²æ¢ç´¢å¤§éƒ¨åˆ†é‡è¦çŠ¶æ€"
                )
                recommendations.append(
                    "ğŸ’¡ å¯ä»¥è€ƒè™‘é™ä½æ¢ç´¢ç‡(epsilon)ä»¥ä¸“æ³¨äºåˆ©ç”¨å­¦åˆ°çš„çŸ¥è¯†"
                )
            elif q_data["state_growth_deceleration"] < 20:
                recommendations.append(
                    "ğŸ” Qè¡¨ä»åœ¨å¿«é€Ÿæ‰©å±•ï¼Œæ¨¡å‹æ­£åœ¨ç§¯ææ¢ç´¢æ–°çŠ¶æ€"
                )
        
        # å­¦ä¹ æ•ˆç‡å»ºè®®
        if "learning_efficiency" in growth_analysis:
            learn_data = growth_analysis["learning_efficiency"]
            if learn_data["win_rate_improvement"] > 5:
                recommendations.append(
                    "ğŸ¯ èƒœç‡æœ‰æ˜¾è‘—æå‡ï¼Œå­¦ä¹ æ•ˆæœè‰¯å¥½"
                )
            elif learn_data["win_rate_improvement"] < 1:
                recommendations.append(
                    "ğŸ“ˆ èƒœç‡æå‡ç¼“æ…¢ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ å‚æ•°"
                )
            
            if learn_data["learning_stability"] > 0.7:
                recommendations.append(
                    "ğŸª å­¦ä¹ è¿‡ç¨‹ç¨³å®šï¼Œæ¨¡å‹æ€§èƒ½ä¸€è‡´"
                )
            else:
                recommendations.append(
                    "ğŸ¢ å­¦ä¹ è¿‡ç¨‹æ³¢åŠ¨è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡"
                )
        
        if not recommendations:
            recommendations.append("ğŸ“Š éœ€è¦æ›´å¤šæ•°æ®è¿›è¡Œæ·±å…¥åˆ†æ")
        
        return recommendations
    
    def generate_report(self, model_path: str, output_file: str = None):
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_model_file(model_path)
        
        if "error" in analysis:
            print(f"âŒ åˆ†æå¤±è´¥: {analysis['error']}")
            return
        
        report = self._format_analysis_report(analysis)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print(report)
    
    def _format_analysis_report(self, analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åˆ†ææŠ¥å‘Š"""
        report = []
        report.append("ğŸ¤– å¼ºåŒ–å­¦ä¹ æ¨¡å‹åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {analysis['file_path']}")
        report.append(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {analysis['total_file_size']:,} å­—èŠ‚ ({analysis['total_file_size']/1024:.1f} KB)")
        report.append("")
        
        # ç»„ä»¶åˆ†æ
        report.append("ğŸ“Š ç»„ä»¶å¤§å°åˆ†æ:")
        report.append("-" * 40)
        for component, info in analysis['components'].items():
            report.append(f"  {component:20s}: {info['size_bytes']:8,} å­—èŠ‚ ({info['size_percentage']:5.1f}%)")
        report.append("")
        
        # Qè¡¨ç»Ÿè®¡
        if "q_table_stats" in analysis:
            report.append("ğŸ§  Qè¡¨ç»Ÿè®¡ä¿¡æ¯:")
            report.append("-" * 40)
            q_stats = analysis["q_table_stats"]
            
            if "total_states" in q_stats:
                # å•Qè¡¨
                report.append(f"  çŠ¶æ€æ€»æ•°: {q_stats['total_states']:,}")
                report.append(f"  çŠ¶æ€-åŠ¨ä½œå¯¹: {q_stats['total_state_action_pairs']:,}")
                report.append(f"  å¹³å‡åŠ¨ä½œæ•°/çŠ¶æ€: {q_stats['avg_actions_per_state']:.2f}")
            else:
                # åŒQè¡¨
                report.append(f"  Qè¡¨1çŠ¶æ€æ•°: {q_stats['q_table_1']['total_states']:,}")
                report.append(f"  Qè¡¨2çŠ¶æ€æ•°: {q_stats['q_table_2']['total_states']:,}")
                report.append(f"  æ€»å”¯ä¸€çŠ¶æ€: {q_stats['combined']['total_unique_states']:,}")
                report.append(f"  çŠ¶æ€é‡å ç‡: {q_stats['combined']['state_overlap_percentage']:.1f}%")
        
        report.append("")
        
        # å­¦ä¹ æŒ‡æ ‡
        report.append("ğŸ“ˆ å­¦ä¹ æŒ‡æ ‡:")
        report.append("-" * 40)
        metrics = analysis["learning_metrics"]
        report.append(f"  æ¸¸æˆæ¬¡æ•°: {metrics['game_count']:,}")
        report.append(f"  èƒœåˆ©æ¬¡æ•°: {metrics['win_count']:,}")
        report.append(f"  èƒœç‡: {metrics['win_rate']:.2f}%")
        report.append(f"  æ€»å¥–åŠ±: {metrics['total_reward']:.2f}")
        report.append(f"  å¹³å‡å¥–åŠ±: {metrics['avg_reward']:.4f}")
        report.append(f"  å½“å‰æ¢ç´¢ç‡: {metrics['current_epsilon']:.4f}")
        report.append("")
        
        # æ•ˆç‡æŒ‡æ ‡
        report.append("âš¡ æ•ˆç‡æŒ‡æ ‡:")
        report.append("-" * 40)
        eff = analysis["efficiency_metrics"]
        report.append(f"  çŠ¶æ€æ•°/æ¸¸æˆ: {eff['states_per_game']:.2f}")
        report.append(f"  Qå€¼æ¡ç›®æ•°/æ¸¸æˆ: {eff['entries_per_game']:.2f}")
        report.append(f"  å¹³å‡çŠ¶æ€è®¿é—®æ¬¡æ•°: {eff['avg_state_visits']:.2f}")
        report.append(f"  å­¦ä¹ å¯†åº¦: {eff['learning_density']:.4f}")
        report.append(f"  æ¢ç´¢æ•ˆç‡: {eff['exploration_efficiency']:.4f}")
        
        return "\n".join(report)

def analyze_model_growth_pattern(models_dir: str = "models"):
    """åˆ†ææ¨¡å‹ç›®å½•ä¸­çš„å¢é•¿æ¨¡å¼"""
    analyzer = ModelAnalyzer()
    
    if not os.path.exists(models_dir):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
        return
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_files = []
    for file in os.listdir(models_dir):
        if file.endswith('.pkl'):
            model_files.append(os.path.join(models_dir, file))
    
    if not model_files:
        print(f"âŒ åœ¨ {models_dir} ä¸­æœªæ‰¾åˆ°pklæ¨¡å‹æ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    for model_file in sorted(model_files):
        print(f"\nğŸ“‹ åˆ†æ: {model_file}")
        print("-" * 50)
        
        analysis = analyzer.analyze_model_file(model_file)
        if "error" not in analysis:
            # ç®€è¦ä¿¡æ¯
            size_kb = analysis['total_file_size'] / 1024
            games = analysis['learning_metrics']['game_count']
            win_rate = analysis['learning_metrics']['win_rate']
            
            if 'q_table_stats' in analysis:
                q_stats = analysis['q_table_stats']
                if 'total_states' in q_stats:
                    states = q_stats['total_states']
                else:
                    states = q_stats['combined']['total_unique_states']
            else:
                states = 0
            
            print(f"  å¤§å°: {size_kb:.1f} KB | æ¸¸æˆ: {games:,} | èƒœç‡: {win_rate:.1f}% | çŠ¶æ€: {states:,}")
        else:
            print(f"  âŒ {analysis['error']}")

if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("ğŸ¤– å¼ºåŒ–å­¦ä¹ æ¨¡å‹åˆ†æå·¥å…·")
    print("=" * 60)
    
    # åˆ†ææ¨¡å‹ç›®å½•
    analyze_model_growth_pattern() 