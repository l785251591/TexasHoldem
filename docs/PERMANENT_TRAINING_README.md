# 🔄 永久自动训练模式

## 📋 功能概述

永久自动训练模式是德州扑克游戏的新增功能，专门为强化学习机器人提供无限循环的训练环境。

## 🎯 主要特性

### ✅ 无限循环训练
- **自动重开新局**: 当所有强化学习机器人没有筹码时，系统会自动重开新的游戏局
- **无需手动干预**: 不需要设置训练轮数限制，可以持续运行
- **优雅停止**: 支持 Ctrl+C 优雅停止训练并保存模型

### ✅ 智能数据管理
- **定期数据清理**: 自动清理历史游戏记录，防止数据库过大
- **可配置清理间隔**: 用户可以设置清理频率（建议1000-5000手）
- **保留重要数据**: 清理时保留最近的训练数据

### ✅ 模型管理
- **定期自动保存**: 按设定间隔自动保存强化学习模型
- **可配置保存间隔**: 用户可以设置保存频率（建议50-100手）
- **训练结束保存**: 训练停止时自动保存最终模型

### ✅ 实时监控
- **训练进度显示**: 实时显示总手牌数、游戏局数、训练速度
- **机器人状态**: 显示每个强化学习机器人的Q表大小、探索率、筹码状态
- **性能统计**: 显示训练时长、平均速度等性能指标

## 🚀 使用方法

### 1. 启动程序
```bash
python main.py
```

### 2. 选择永久训练模式
在主菜单中选择选项 `3. 🔄 永久自动训练模式 (无限循环)`

### 3. 配置训练参数
- **模型保存间隔**: 每N手保存一次模型（默认: 50手）
- **数据清理间隔**: 每N手清理一次历史数据（默认: 1000手）
- **RL机器人数量**: 参与训练的强化学习机器人数量（1-4个，默认: 2个）

### 4. 开始训练
确认配置后，系统将自动开始永久训练模式

### 5. 停止训练
按 `Ctrl+C` 优雅停止训练

## ⚙️ 推荐配置

| 参数 | 推荐值 | 说明 |
|------|--------|------|
| 模型保存间隔 | 50-100手 | 平衡性能和数据安全 |
| 数据清理间隔 | 1000-5000手 | 防止数据库过大 |
| RL机器人数量 | 2个 | 充分竞争学习 |

## 📊 训练监控

### 进度信息
- 总手牌数: 累计训练的手牌数量
- 总游戏局数: 累计完成的游戏局数
- 当前局手牌: 当前游戏局的手牌数
- 训练速度: 每秒处理的手牌数
- 运行时长: 总训练时间

### 机器人状态
- Q表大小: 学习到的状态数量
- 探索率(ε): 当前的探索vs利用比例
- 筹码状态: 当前筹码数量和存活状态

## �� 数据库管理

### 自动清理机制（按大小清理 - 专为永久训练优化）
- **触发条件**: 
  - 定期检查：每50手检查一次数据库大小
  - 定时清理：达到设定的清理间隔（默认1000手）
  - 立即清理：数据库超过10MB时立即清理
- **清理策略**: 
  - **目标大小**: 10MB（可配置）
  - **清理方式**: 按记录时间删除最旧的数据，保留最新数据
  - **清理比例**: 动态计算，目标是将数据库减小到目标大小的80%
  - **优先级**: bot_learning_data > player_actions > hands > games
- **清理效果**: 
  - 自动回收空间（执行VACUUM）
  - 显示清理前后的大小对比
  - 显示清理的记录数量和减少比例
- **安全保障**: 
  - 限制清理比例在10%-90%之间
  - 保留最新的训练数据
  - 异常处理和回滚机制

### 清理优势
相比按天数清理的优势：
- **精确控制**: 直接控制数据库大小，不受训练频率影响
- **性能优化**: 保持数据库在合理大小，确保查询性能
- **存储友好**: 防止磁盘空间不足
- **训练连续**: 不会因为数据库过大而影响训练速度

### 清理示例
```
🚨 数据库超过10MB (107.7MB)，立即清理...
✅ 紧急清理完成: 107.7MB → 10.5MB
📊 清理了 385,973 条记录
```

## 🔧 技术实现

### 核心函数
- `setup_permanent_training_mode()`: 设置永久训练模式
- `start_permanent_training()`: 执行永久训练逻辑
- `_create_training_game()`: 创建训练游戏实例
- `_rebalance_chips_for_training()`: 重新平衡筹码

### 关键特性
- **训练模式标记**: 设置 `game.training_mode = True` 跳过人工等待
- **异常处理**: 捕获并处理训练过程中的异常
- **资源管理**: 定期清理和保存，防止资源泄漏

## 🚨 注意事项

1. **长时间运行**: 此模式设计为长时间运行，请确保系统稳定
2. **磁盘空间**: 定期检查数据库大小，确保有足够的磁盘空间
3. **性能监控**: 关注CPU和内存使用情况
4. **模型备份**: 重要的训练模型建议定期备份

## 🆚 与普通训练模式的区别

| 特性 | 普通训练模式 | 永久训练模式 |
|------|-------------|-------------|
| 训练轮数 | 需要设置限制 | 无限循环 |
| 重开新局 | 手动 | 自动 |
| 数据清理 | 手动 | 自动 |
| 适用场景 | 短期测试 | 长期训练 |
| 用户干预 | 较多 | 最少 |

## 📈 预期效果

使用永久自动训练模式，强化学习机器人将能够：
- 获得更多的训练数据
- 学习更复杂的策略
- 提高决策能力
- 适应不同的对手风格

通过持续的训练，机器人的德州扑克技能将不断提升！ 